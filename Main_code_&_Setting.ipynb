{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Dataset : https://www.kaggle.com/datasets/ssarkar445/covid-19-xray-and-ct-scan-image-dataset"
      ],
      "metadata": {
        "id": "HUsKK0Ko0D9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset, random_split, ConcatDataset\n",
        "import copy\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "import torchvision.datasets\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "dataset_paths = {\n",
        "    \"CT\": \"/home/ealam/MDCL/EXP1/archive (2)/COVID-19 Dataset/CT\",\n",
        "    \"X-ray\": \"/home/ealam/MDCL/EXP1/archive (2)/COVID-19 Dataset/X-ray\"\n",
        "}\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485], std=[0.229])\n",
        "])\n",
        "\n",
        "\n",
        "datasets = {}\n",
        "for dataset_type, dataset_path in dataset_paths.items():\n",
        "    datasets[dataset_type] = torchvision.datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "\n",
        "\n",
        "ct_dataset = datasets[\"CT\"]\n",
        "ct_class0_indices = [idx for idx, (img, label) in enumerate(ct_dataset.imgs) if label == 0]\n",
        "ct_class1_indices = [idx for idx, (img, label) in enumerate(ct_dataset.imgs) if label == 1]\n",
        "selected_ct_indices = ct_class0_indices[:399] + ct_class1_indices[:146]\n",
        "\n",
        "\n",
        "ct_train_size = int(0.8 * len(selected_ct_indices))\n",
        "ct_test_size = len(selected_ct_indices) - ct_train_size\n",
        "ct_train_dataset, ct_test_dataset = random_split(Subset(ct_dataset, selected_ct_indices), [ct_train_size, ct_test_size])\n",
        "\n",
        "\n",
        "xray_dataset = datasets[\"X-ray\"]\n",
        "xray_class0_indices = [idx for idx, (img, label) in enumerate(xray_dataset.imgs) if label == 0]\n",
        "xray_class1_indices = [idx for idx, (img, label) in enumerate(xray_dataset.imgs) if label == 1]\n",
        "selected_xray_indices = xray_class0_indices[:223] + xray_class1_indices[:1341]\n",
        "\n",
        "\n",
        "xray_train_size = int(0.8 * len(selected_xray_indices))\n",
        "xray_test_size = len(selected_xray_indices) - xray_train_size\n",
        "xray_train_dataset, xray_test_dataset = random_split(Subset(xray_dataset, selected_xray_indices), [xray_train_size, xray_test_size])\n",
        "\n",
        "\n",
        "client_clusters_ct = {0: list(range(len(ct_train_dataset))), 1: list(range(len(ct_train_dataset)))}\n",
        "\n",
        "client_clusters_xray = {2: list(range(len(xray_train_dataset))), 3: list(range(len(xray_train_dataset)))}\n",
        "\n",
        "\n",
        "class OriginalVGG16(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(OriginalVGG16, self).__init__()\n",
        "        self.features = models.vgg16(pretrained=True).features\n",
        "        self.classifier = models.vgg16(pretrained=True).classifier\n",
        "\n",
        "\n",
        "        self.classifier._modules['6'] = nn.Linear(4096, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2, logits=True, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        if self.logits:\n",
        "            BCE_loss = nn.functional.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        else:\n",
        "            BCE_loss = nn.functional.binary_cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
        "        if self.reduction == 'mean':\n",
        "            return torch.mean(F_loss)\n",
        "        elif self.reduction == 'sum':\n",
        "            return torch.sum(F_loss)\n",
        "        else:\n",
        "            return F_loss\n",
        "\n",
        "\n",
        "def local_train(model, train_loader, epochs, criterion, optimizer):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "\n",
        "\n",
        "            target_onehot = torch.zeros_like(output)\n",
        "            target_onehot.scatter_(1, target.view(-1, 1), 1)\n",
        "\n",
        "            loss = criterion(output, target_onehot)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "def evaluate_model_per_class(model, test_loader):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        y_true.extend(target.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "    precision = precision_score(y_true, y_pred, average=None)\n",
        "    recall = recall_score(y_true, y_pred, average=None)\n",
        "    f1 = f1_score(y_true, y_pred, average=None)\n",
        "    return precision, recall, f1\n",
        "\n",
        "\n",
        "lr = 0.0001\n",
        "local_epochs = 17\n",
        "global_epochs = 25\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "combined_train_dataset = ConcatDataset([Subset(ct_train_dataset, indices) for indices in client_clusters_ct.values()] +\n",
        "                                       [Subset(xray_train_dataset, indices) for indices in client_clusters_xray.values()])\n",
        "\n",
        "\n",
        "combined_client_clusters = {key: value for key, value in client_clusters_ct.items()}\n",
        "for key, value in client_clusters_xray.items():\n",
        "    combined_client_clusters[key + len(client_clusters_ct)] = value\n",
        "\n",
        "\n",
        "shared_model_combined = OriginalVGG16(num_classes=2).to(device)\n",
        "\n",
        "\n",
        "criterion_combined = FocalLoss(alpha=1, gamma=2)\n",
        "optimizer_combined = torch.optim.Adam(shared_model_combined.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "for global_epoch in range(global_epochs):\n",
        "    for cluster_id, cluster_indices in combined_client_clusters.items():\n",
        "        local_model_combined = copy.deepcopy(shared_model_combined)\n",
        "        train_loader_combined = DataLoader(Subset(combined_train_dataset, cluster_indices), batch_size=batch_size, shuffle=True)\n",
        "        local_train(local_model_combined, train_loader_combined, local_epochs, criterion_combined, optimizer_combined)\n",
        "        shared_model_combined.load_state_dict(local_model_combined.state_dict())\n",
        "\n",
        "\n",
        "        for shared_param, local_param in zip(shared_model_combined.parameters(), local_model_combined.parameters()):\n",
        "            shared_param.data.copy_((shared_param.data + local_param.data) / 2.0)\n",
        "\n",
        "\n",
        "test_loader_ct = DataLoader(ct_test_dataset, batch_size=batch_size, shuffle=False)\n",
        "precision_ct, recall_ct, f1_ct = evaluate_model_per_class(shared_model_combined, test_loader_ct)\n",
        "\n",
        "\n",
        "print(\"Evaluation Metrics for CT Dataset:\")\n",
        "print(f'Class 0:')\n",
        "print(f'Precision: {precision_ct[0]:.2f}')\n",
        "print(f'Recall: {recall_ct[0]:.2f}')\n",
        "print(f'F1 Score: {f1_ct[0]:.2f}')\n",
        "print(f'Class 1:')\n",
        "print(f'Precision: {precision_ct[1]:.2f}')\n",
        "print(f'Recall: {recall_ct[1]:.2f}')\n",
        "print(f'F1 Score: {f1_ct[1]:.2f}')\n",
        "\n",
        "\n",
        "test_loader_xray = DataLoader(xray_test_dataset, batch_size=batch_size, shuffle=False)\n",
        "precision_xray, recall_xray, f1_xray = evaluate_model_per_class(shared_model_combined, test_loader_xray)\n",
        "\n",
        "\n",
        "print(\"\\nEvaluation Metrics for X-ray Dataset:\")\n",
        "print(f'Class 0:')\n",
        "print(f'Precision: {precision_xray[0]:.2f}')\n",
        "print(f'Recall: {recall_xray[0]:.2f}')\n",
        "print(f'F1 Score: {f1_xray[0]:.2f}')\n",
        "print(f'Class 1:')\n",
        "print(f'Precision: {precision_xray[1]:.2f}')\n",
        "print(f'Recall: {recall_xray[1]:.2f}')\n",
        "print(f'F1 Score: {f1_xray[1]:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx2WGnM1sbEq",
        "outputId": "ff6bed20-6092-4840-a76c-3e659d979e45"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics for CT Dataset:\n",
            "Class 0:\n",
            "Precision: 0.96\n",
            "Recall: 0.92\n",
            "F1 Score: 0.95\n",
            "Class 1:\n",
            "Precision: 0.97\n",
            "Recall: 0.77\n",
            "F1 Score: 0.86\n",
            "\n",
            "Evaluation Metrics for X-ray Dataset:\n",
            "Class 0:\n",
            "Precision: 1.0\n",
            "Recall: 0.93\n",
            "F1 Score: 0.96\n",
            "Class 1:\n",
            "Precision: 0.93\n",
            "Recall: 0.89\n",
            "F1 Score: 0.91\n"
          ]
        }
      ]
    }
  ]
}